# -*- coding: utf-8 -*-
"""
Pinecone GMP ë²¡í„° DB ê²€ì¦ ë° í…ŒìŠ¤íŠ¸ í†µí•© ë„êµ¬
- ê¸°ë³¸ í†µê³„ í™•ì¸
- ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ
- ì‹¤ì œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
- ë©”íƒ€ë°ì´í„° ë¶„ì„
- ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì§€ì›

ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
python check_pinecone.py --mode search --query "í’ˆì§ˆ" --namespace new-gmp-fda/fda-sop ì¤‘ 1ê°œ
"""

import os
import random
import argparse
from collections import Counter
from pinecone import Pinecone
from langchain.embeddings.openai import OpenAIEmbeddings
from dotenv import load_dotenv

load_dotenv()

# ==================== ì„¤ì • ====================
INDEX_NAME = "gmp-sop-vectordb"
EMBEDDING_MODEL = "text-embedding-3-small"  # ë˜ëŠ” text-embedding-ada-002
EMBEDDING_DIMENSION = 1536  # OpenAI ì„ë² ë”© ì°¨ì›


def log(msg: str) -> None:
    import time
    timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] {msg}")


def get_pinecone_connection():
    pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
    return pc.Index(INDEX_NAME)


def get_embedder():
    return OpenAIEmbeddings(
        model=EMBEDDING_MODEL,
        openai_api_key=os.getenv("OPENAI_API_KEY")
    )

# ==================== 1. ê¸°ë³¸ í†µê³„ í™•ì¸ ====================
def check_basic_stats():
    log("ê¸°ë³¸ í†µê³„ í™•ì¸ ì‹œì‘")
    index = get_pinecone_connection()
    stats = index.describe_index_stats()
    print("\n" + "="*50)
    print("ğŸ“Š PINECONE ì¸ë±ìŠ¤ ê¸°ë³¸ í†µê³„")
    print("="*50)
    print(f"ì´ ë²¡í„° ìˆ˜: {stats['total_vector_count']:,}ê°œ")
    print(f"ì°¨ì›: {stats['dimension']}")
    print(f"ë©”íŠ¸ë¦­: {stats['metric']}")
    print(f"ì¸ë±ìŠ¤ ì‚¬ìš©ë¥ : {stats['index_fullness']:.2%}")
    if 'namespaces' in stats and stats['namespaces']:
        print(f"\nğŸ“ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë³„ í†µê³„:")
        for ns, ns_stats in stats['namespaces'].items():
            ns_name = ns if ns else "ê¸°ë³¸"
            print(f"  {ns_name}: {ns_stats['vector_count']:,}ê°œ ë²¡í„°")
    else:
        print("\nğŸ“ ë„¤ì„ìŠ¤í˜ì´ìŠ¤: ê¸°ë³¸ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë§Œ ì‚¬ìš©")
    return stats

# ==================== 2. ìƒ˜í”Œ ë°ì´í„° í™•ì¸ ====================
def check_sample_data(num_samples: int = 5, namespace: str = None):
    log(f"ìƒ˜í”Œ ë°ì´í„° {num_samples}ê°œ í™•ì¸ ì‹œì‘")
    if namespace:
        log(f"ë„¤ì„ìŠ¤í˜ì´ìŠ¤: {namespace}")
    index = get_pinecone_connection()
    random_vector = [random.random() for _ in range(EMBEDDING_DIMENSION)]
    results = index.query(
        vector=random_vector,
        top_k=num_samples,
        namespace=namespace,
        include_metadata=True,
        include_values=False
    )
    print("\n" + "="*50)
    print(f"ğŸ” ìƒ˜í”Œ ë°ì´í„° ({len(results['matches'])}ê°œ)")
    if namespace:
        print(f"ğŸ·ï¸ ë„¤ì„ìŠ¤í˜ì´ìŠ¤: {namespace}")
    print("="*50)
    for i, match in enumerate(results['matches'], 1):
        print(f"\n{i}. ID: {match['id']}")
        print(f"   ìœ ì‚¬ë„ ì ìˆ˜: {match['score']:.4f}")
        if 'metadata' in match:
            metadata = match['metadata']
            print(f"   ğŸ“„ ì œëª©: {metadata.get('title', 'N/A')}")
            print(f"   ğŸ“‚ ì¶œì²˜: {metadata.get('source_path', 'N/A')}")
            print(f"   ğŸ“‹ ì„¹ì…˜: {metadata.get('section_title', 'N/A')}")
            print(f"   ğŸ›ï¸ ê´€í• : {metadata.get('jurisdiction', 'N/A')}")
            if 'text' in metadata:
                text = metadata['text']
                display_text = text[:200] + "..." if len(text) > 200 else text
                print(f"   ğŸ“ ë‚´ìš©: {display_text}")
        print("-" * 40)
    return results

# ==================== 3. ì‹¤ì œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ====================
def test_search(queries: list = None, top_k: int = 5, namespace: str = None):
    log("ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    if namespace:
        log(f"ë„¤ì„ìŠ¤í˜ì´ìŠ¤: {namespace}")
    if queries is None:
        queries = [
            "GMP í’ˆì§ˆê´€ë¦¬",
            "ë°¸ë¦¬ë°ì´ì…˜",
            "ë¬¸ì„œê´€ë¦¬", 
            "ë³€ê²½ê´€ë¦¬",
            "ìœ„í—˜í‰ê°€"
        ]
    index = get_pinecone_connection()
    embedder = get_embedder()
    print("\n" + "="*50)
    print("ğŸ” ì‹¤ì œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    if namespace:
        print(f"ğŸ·ï¸ ë„¤ì„ìŠ¤í˜ì´ìŠ¤: {namespace}")
    print("="*50)
    for query_idx, query in enumerate(queries, 1):
        print(f"\nğŸ” ê²€ìƒ‰ {query_idx}: '{query}'")
        print("-" * 30)
        try:
            query_vector = embedder.embed_query(query)
            results = index.query(
                vector=query_vector,
                top_k=top_k,
                namespace=namespace,
                include_metadata=True,
                include_values=False
            )
            print(f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(results['matches'])}ê°œ ë°œê²¬")
            for i, match in enumerate(results['matches'], 1):
                print(f"\n  {i}. ì ìˆ˜: {match['score']:.4f}")
                if 'metadata' in match:
                    metadata = match['metadata']
                    title = metadata.get('title', 'N/A')
                    section = metadata.get('section_title', 'N/A')
                    jurisdiction = metadata.get('jurisdiction', 'N/A')
                    print(f"     ì œëª©: {title}")
                    print(f"     ì„¹ì…˜: {section}")
                    print(f"     ê´€í• : {jurisdiction}")
                    if 'text' in metadata:
                        text = metadata['text']
                        display_text = text[:120] + "..." if len(text) > 120 else text
                        print(f"     ë‚´ìš©: {display_text}")
                if i < len(results['matches']):
                    print("     " + "-" * 25)
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        if query_idx < len(queries):
            print("\n" + "="*40)
    return True

# ==================== 4. ë©”íƒ€ë°ì´í„° ë¶„ì„ ====================
def analyze_metadata(sample_count: int = 100, namespace: str = None):
    log(f"ë©”íƒ€ë°ì´í„° ë¶„ì„ ì‹œì‘ (ìƒ˜í”Œ: {sample_count}ê°œ)")
    if namespace:
        log(f"ë„¤ì„ìŠ¤í˜ì´ìŠ¤: {namespace}")
    index = get_pinecone_connection()
    all_metadata = []
    batch_size = 50
    num_batches = (sample_count + batch_size - 1) // batch_size
    for batch in range(num_batches):
        random_vector = [random.random() for _ in range(EMBEDDING_DIMENSION)]
        current_batch_size = min(batch_size, sample_count - len(all_metadata))
        results = index.query(
            vector=random_vector,
            top_k=current_batch_size,
            namespace=namespace,
            include_metadata=True
        )
        for match in results['matches']:
            if 'metadata' in match:
                all_metadata.append(match['metadata'])
        if len(all_metadata) >= sample_count:
            break
    print("\n" + "="*50)
    print(f"ğŸ“ˆ ë©”íƒ€ë°ì´í„° ë¶„ì„ (ìƒ˜í”Œ: {len(all_metadata)}ê°œ)")
    if namespace:
        print(f"ğŸ·ï¸ ë„¤ì„ìŠ¤í˜ì´ìŠ¤: {namespace}")
    print("="*50)
    jurisdictions = [m.get('jurisdiction') for m in all_metadata if m.get('jurisdiction')]
    if jurisdictions:
        jurisdiction_counts = Counter(jurisdictions)
        print(f"\nğŸ›ï¸ ê´€í•  ì§€ì—­ë³„ ë¬¸ì„œ ìˆ˜:")
        for jurisdiction, count in jurisdiction_counts.most_common():
            percentage = (count / len(jurisdictions)) * 100
            print(f"  {jurisdiction}: {count}ê°œ ({percentage:.1f}%)")
    titles = [m.get('title') for m in all_metadata if m.get('title')]
    if titles:
        title_counts = Counter(titles)
        print(f"\nğŸ“„ ì£¼ìš” ë¬¸ì„œ ì œëª© (ìƒìœ„ 10ê°œ):")
        for i, (title, count) in enumerate(title_counts.most_common(10), 1):
            percentage = (count / len(titles)) * 100
            print(f"  {i:2d}. {title}: {count}ê°œ ({percentage:.1f}%)")
    versions = [m.get('doc_version') for m in all_metadata if m.get('doc_version')]
    if versions:
        version_counts = Counter(versions)
        print(f"\nğŸ“‹ ë¬¸ì„œ ë²„ì „ë³„ ë¶„í¬:")
        for version, count in version_counts.most_common():
            percentage = (count / len(versions)) * 100
            print(f"  {version}: {count}ê°œ ({percentage:.1f}%)")
    sections = [m.get('section_title') for m in all_metadata if m.get('section_title')]
    if sections:
        section_counts = Counter(sections)
        print(f"\nğŸ“‘ ì£¼ìš” ì„¹ì…˜ (ìƒìœ„ 10ê°œ):")
        for i, (section, count) in enumerate(section_counts.most_common(10), 1):
            percentage = (count / len(sections)) * 100
            print(f"  {i:2d}. {section}: {count}ê°œ ({percentage:.1f}%)")
    doc_types = []
    for m in all_metadata:
        source = m.get('source_path', '')
        if '.pdf' in source.lower():
            doc_types.append('PDF')
        elif '.docx' in source.lower() or '.doc' in source.lower():
            doc_types.append('Word')
        elif '.txt' in source.lower():
            doc_types.append('Text')
        else:
            doc_types.append('ê¸°íƒ€')
    if doc_types:
        type_counts = Counter(doc_types)
        print(f"\nğŸ“ ë¬¸ì„œ í˜•íƒœë³„ ë¶„í¬:")
        for doc_type, count in type_counts.most_common():
            percentage = (count / len(doc_types)) * 100
            print(f"  {doc_type}: {count}ê°œ ({percentage:.1f}%)")
    return all_metadata

# ==================== ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë³„ ê²€ìƒ‰ ====================
def search_all_namespaces(query: str, top_k: int = 3):
    log(f"ëª¨ë“  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ '{query}' ê²€ìƒ‰")
    index = get_pinecone_connection()
    embedder = get_embedder()
    stats = index.describe_index_stats()
    namespaces = list(stats.get('namespaces', {}).keys()) if stats.get('namespaces') else [None]
    if not namespaces or (len(namespaces) == 1 and namespaces[0] is None):
        print("\nğŸ“ ì‚¬ìš© ê°€ëŠ¥í•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
        namespaces = [None]
    query_vector = embedder.embed_query(query)
    print(f"\nğŸ” ì „ì²´ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê²€ìƒ‰: '{query}'")
    print("="*60)
    for ns in namespaces:
        ns_name = ns if ns else "ê¸°ë³¸"
        print(f"\nğŸ“ ë„¤ì„ìŠ¤í˜ì´ìŠ¤: {ns_name}")
        print("-" * 30)
        try:
            results = index.query(
                vector=query_vector,
                top_k=top_k,
                namespace=ns,
                include_metadata=True,
                include_values=False
            )
            print(f"ğŸ“Š ê²°ê³¼: {len(results['matches'])}ê°œ")
            for i, match in enumerate(results['matches'], 1):
                print(f"  {i}. ì ìˆ˜: {match['score']:.4f}")
                if 'metadata' in match:
                    metadata = match['metadata']
                    title = metadata.get('title', 'N/A')
                    jurisdiction = metadata.get('jurisdiction', 'N/A')
                    print(f"     ì œëª©: {title[:50]}..." if len(title) > 50 else f"     ì œëª©: {title}")
                    print(f"     ê´€í• : {jurisdiction}")
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")

# ==================== ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ ====================
def run_all_checks(namespace: str = None):
    print("ğŸš€ Pinecone GMP ë²¡í„° DB ì¢…í•© ê²€ì¦ ì‹œì‘")
    if namespace:
        print(f"ğŸ·ï¸ ë„¤ì„ìŠ¤í˜ì´ìŠ¤: {namespace}")
    print("="*60)
    try:
        stats = check_basic_stats()
        if stats['total_vector_count'] == 0:
            print("\nâŒ ë²¡í„°ê°€ ì €ì¥ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤!")
            return False
        check_sample_data(num_samples=3, namespace=namespace)
        test_search(top_k=3, namespace=namespace)
        analyze_metadata(sample_count=50, namespace=namespace)
        print("\n" + "="*60)
        print("âœ… ëª¨ë“  ê²€ì¦ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("="*60)
        return True
    except Exception as e:
        print(f"\nâŒ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description="Pinecone GMP ë²¡í„° DB ê²€ì¦ ë„êµ¬ (OpenAI ì„ë² ë”©)")
    parser.add_argument("--mode", choices=['all', 'stats', 'sample', 'search', 'metadata', 'search-all'], 
                       default='all', help="ì‹¤í–‰í•  ê²€ì¦ ëª¨ë“œ")
    parser.add_argument("--query", type=str, help="ê²€ìƒ‰í•  ì¿¼ë¦¬ (search ëª¨ë“œìš©)")
    parser.add_argument("--samples", type=int, default=5, help="ìƒ˜í”Œ ìˆ˜")
    parser.add_argument("--top-k", type=int, default=5, help="ê²€ìƒ‰ ê²°ê³¼ ìˆ˜")
    parser.add_argument("--namespace", type=str, help="ê²€ìƒ‰í•  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ (ì˜ˆ: fda-new-gmp)")
    args = parser.parse_args()
    try:
        if args.mode == 'all':
            run_all_checks(namespace=args.namespace)
        elif args.mode == 'stats':
            check_basic_stats()
        elif args.mode == 'sample':
            check_sample_data(args.samples, namespace=args.namespace)
        elif args.mode == 'search':
            queries = [args.query] if args.query else None
            test_search(queries, args.top_k, namespace=args.namespace)
        elif args.mode == 'search-all':
            if not args.query:
                args.query = "GMP í’ˆì§ˆê´€ë¦¬"
            search_all_namespaces(args.query, args.top_k)
        elif args.mode == 'metadata':
            analyze_metadata(args.samples, namespace=args.namespace)
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()
